{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Assignment Five: Evaluation and Multi-Layer Perceptron\n",
    "## Rupal Sanghavi, Omar Roa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', DeprecationWarning)\n",
    "%matplotlib inline \n",
    "%load_ext memory_profiler\n",
    "from sklearn.metrics import make_scorer\n",
    "from scipy.special import expit\n",
    "import time\n",
    "import math\n",
    "from memory_profiler import memory_usage\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression as SKLogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "target_classifier = 'Shopping centres'\n",
    "df = pd.read_csv('responses.csv', sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove rows whose target classfier value is NaN\n",
    "df_cleaned_classifier = df[np.isfinite(df[target_classifier])]\n",
    "# change NaN number values to the mean\n",
    "df_imputed = df_cleaned_classifier.fillna(df.mean())\n",
    "# get categorical features\n",
    "object_features = list(df_cleaned_classifier.select_dtypes(include=['object']).columns)\n",
    "# one hot encode categorical features\n",
    "one_hot_df = pd.concat([pd.get_dummies(df_imputed[col],prefix=col) for col in object_features], axis=1)\n",
    "# drop object features from imputed dataframe\n",
    "df_imputed_dropped = df_imputed.drop(object_features, 1)\n",
    "frames = [df_imputed_dropped, one_hot_df]\n",
    "# concatenate both frames by columns\n",
    "df_fixed = pd.concat(frames, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics To Evaluate Algorithm's Generalization Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make_scorer(get_confusion_costTot, greater_is_better=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Research on Cost Matrix\n",
    "# http://www.ibm.com/support/knowledgecenter/SSEPGG_11.1.0/com.ibm.im.model.doc/c_cost_matrix.html\n",
    "\n",
    "cost_matrix = np.matrix([[0,1,2,3,4],\n",
    "[1,0,1,2,3],\n",
    "[3,1,0,1,2],\n",
    "[5,3,1,0,1],\n",
    "[7,5,2,1,0]])\n",
    "\n",
    "def get_confusion_costTot(confusion_matrix, cost_matrix):\n",
    "    score = np.sum(confusion_matrix*cost_matrix)\n",
    "    return score\n",
    "\n",
    "confusion_scorer = make_scorer(get_confusion_costTot, greater_is_better=False)\n",
    "confusion_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Implementation of Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=10, random_state=None, shuffle=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# we want to predict the X and y data as follows:\n",
    "if target_classifier in df_fixed:\n",
    "    y = df_fixed[target_classifier].values # get the label we want\n",
    "    del df_fixed[target_classifier] # get rid of the class label\n",
    "    X = df_fixed.values # use everything else to predict!\n",
    "\n",
    "X = X/5\n",
    "num_folds = 10\n",
    "\n",
    "cv_object = StratifiedKFold(n_splits= num_folds, random_state=None, shuffle=True)\n",
    "cv_object.split(X,y)\n",
    "\n",
    "print(cv_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1. ,  0.6,  0.4, ...,  0.2,  0.2,  0. ],\n",
       "       [ 0.8,  0.8,  0.4, ...,  0. ,  0.2,  0. ],\n",
       "       [ 1. ,  1. ,  0.4, ...,  0. ,  0.2,  0. ],\n",
       "       ..., \n",
       "       [ 0.8,  0.6,  0.2, ...,  0. ,  0.2,  0. ],\n",
       "       [ 1. ,  0.6,  0.6, ...,  0. ,  0.2,  0. ],\n",
       "       [ 1. ,  1. ,  0.8, ...,  0.2,  0. ,  0.2]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example adapted from https://github.com/rasbt/python-machine-learning-book/blob/master/code/ch12/ch12.ipynb\n",
    "# Original Author: Sebastian Raschka\n",
    "# This is the optional book we use in the course, excellent intuitions and straightforward programming examples\n",
    "# please note, however, that this code has been manipulated to reflect our assumptions and notation.\n",
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "# start with a simple base classifier, which can't be fit or predicted\n",
    "# it only has internal classes to be used by classes that will subclass it\n",
    "class TwoLayerPerceptronBase(object):\n",
    "    def __init__(self, n_hidden=30,\n",
    "                 C=0.0, epochs=500, eta=0.001, random_state=None, nonlinearity = \"sigmoid\"):\n",
    "        np.random.seed(random_state)\n",
    "        self.n_hidden = n_hidden\n",
    "        self.l2_C = C\n",
    "        self.epochs = epochs\n",
    "        self.eta = eta\n",
    "        self.nonlinearity = nonlinearity\n",
    "        self.params = {}\n",
    "        \n",
    "    @staticmethod\n",
    "    def _encode_labels(y):\n",
    "        \"\"\"Encode labels into one-hot representation\"\"\"\n",
    "        onehot = pd.get_dummies(y).values.T\n",
    "            \n",
    "        return onehot\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize weights with small random numbers.\"\"\"\n",
    "        W1_num_elems = (self.n_features_ + 1)*self.n_hidden\n",
    "        W1 = np.random.uniform(-1.0, 1.0,size=W1_num_elems)\n",
    "        W1 = W1.reshape(self.n_hidden, self.n_features_ + 1) # reshape to be W\n",
    "        \n",
    "        W2_num_elems = (self.n_hidden + 1)*self.n_output_\n",
    "        W2 = np.random.uniform(-1.0, 1.0, size=W2_num_elems)\n",
    "        W2 = W2.reshape(self.n_output_, self.n_hidden + 1)\n",
    "        return W1, W2\n",
    "    \n",
    "    @staticmethod\n",
    "    def _sigmoid(z):\n",
    "        \"\"\"Use scipy.special.expit to avoid overflow\"\"\"\n",
    "        # 1.0 / (1.0 + np.exp(-z))\n",
    "        return expit(z)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _add_bias_unit(X, how='column'):\n",
    "        \"\"\"Add bias unit (column or row of 1s) to array at index 0\"\"\"\n",
    "        if how == 'column':\n",
    "            ones = np.ones((X.shape[0], 1))\n",
    "            X_new = np.hstack((ones, X))\n",
    "        elif how == 'row':\n",
    "            ones = np.ones((1, X.shape[1]))\n",
    "            X_new = np.vstack((ones, X))\n",
    "        return X_new\n",
    "    \n",
    "    @staticmethod\n",
    "    def _L2_reg(lambda_, W1, W2):\n",
    "        \"\"\"Compute L2-regularization cost\"\"\"\n",
    "        # only compute for non-bias terms\n",
    "        return (lambda_/2.0) * np.sqrt(np.mean(W1[:, 1:] ** 2) + np.mean(W2[:, 1:] ** 2))\n",
    "    \n",
    "    def _cost(self,A3,Y_enc,W1,W2):\n",
    "        '''Get the objective function value'''\n",
    "        cost = np.mean((Y_enc-A3)**2)\n",
    "        L2_term = self._L2_reg(self.l2_C, W1, W2)\n",
    "        return cost + L2_term\n",
    "    \n",
    "    def _feedforward(self, X, W1, W2):\n",
    "        \"\"\"Compute feedforward step\n",
    "        \"\"\"\n",
    "        A1 = self._add_bias_unit(X, how='column')\n",
    "        Z1 = W1 @ A1.T\n",
    "        if(self.nonlinearity == \"sigmoid\"):\n",
    "            A2 = self._sigmoid(Z1)\n",
    "            A2 = self._add_bias_unit(A2, how='row')\n",
    "            Z2 = W2 @ A2\n",
    "            A3 = self._sigmoid(Z2)\n",
    "        else:\n",
    "            A2 = Z1\n",
    "            A2 = self._add_bias_unit(A2, how='row')\n",
    "            Z2 = W2 @ A2\n",
    "            A3 = Z2\n",
    "        return A1, Z1, A2, Z2, A3\n",
    "    \n",
    "    def _get_gradient(self, A1, A2, A3, Z1, Z2, Y_enc, W1, W2):\n",
    "        \"\"\" Compute gradient step using backpropagation.\n",
    "        \"\"\"\n",
    "        # vectorized backpropagation\n",
    "        if(self.nonlinearity == \"sigmoid\"):\n",
    "            sigma3 = -2*(Y_enc-A3)*A3*(1-A3)\n",
    "            sigma2 = (W2.T @ sigma3)*A2*(1-A2)\n",
    "        else:\n",
    "            sigma3 = -2*(Y_enc-A3)\n",
    "            sigma2 = (W2.T @ sigma3)\n",
    "            \n",
    "        grad1 = sigma2[1:,:] @ A1\n",
    "        grad2 = sigma3 @ A2.T\n",
    "        \n",
    "        # regularize weights that are not bias terms\n",
    "        grad1[:, 1:] += W1[:, 1:] * self.l2_C\n",
    "        grad2[:, 1:] += W2[:, 1:] * self.l2_C\n",
    "\n",
    "        return grad1, grad2\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class labels\"\"\"\n",
    "        _, _, _, _, A3 = self._feedforward(X, self.W1, self.W2)\n",
    "        y_pred = np.argmax(A3, axis=0)\n",
    "        return y_pred\n",
    "    def get_params(self,deep=False):\n",
    "        return dict(n_hidden=self.n_hidden, C=self.l2_C, nonlinearity=self.nonlinearity)\n",
    "\n",
    "    def set_params(self,**kwds):\n",
    "        print(kwds)\n",
    "        self.n_hidden = kwds['n_hidden']\n",
    "        self.C = kwds['C']\n",
    "        self.nonlinearity = kwds['nonlinearity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# just start with the vectorized version and minibatch\n",
    "class TLPMiniBatch(TwoLayerPerceptronBase):\n",
    "    def __init__(self, alpha=0.0, decrease_const=0.0, shuffle=True, \n",
    "                 minibatches=1, **kwds):        \n",
    "        # need to add to the original initializer \n",
    "        self.alpha = alpha\n",
    "        self.decrease_const = decrease_const\n",
    "        self.shuffle = shuffle\n",
    "        self.minibatches = minibatches\n",
    "        # but keep other keywords\n",
    "        super().__init__(**kwds)\n",
    "        \n",
    "    \n",
    "    def fit(self, X, y, print_progress=False):\n",
    "        \"\"\" Learn weights from training data. With mini-batch\"\"\"\n",
    "        X_data, y_data = X.copy(), y.copy()\n",
    "        Y_enc = self._encode_labels(y)\n",
    "        \n",
    "        # init weights and setup matrices\n",
    "        self.n_features_ = X_data.shape[1]\n",
    "        self.n_output_ = Y_enc.shape[0]\n",
    "        self.W1, self.W2 = self._initialize_weights()\n",
    "\n",
    "        delta_W1_prev = np.zeros(self.W1.shape)\n",
    "        delta_W2_prev = np.zeros(self.W2.shape)\n",
    "\n",
    "        self.cost_ = []\n",
    "        self.score_ = []\n",
    "        for i in range(self.epochs):\n",
    "\n",
    "            # adaptive learning rate\n",
    "            self.eta /= (1 + self.decrease_const*i)\n",
    "\n",
    "            if print_progress>0 and (i+1)%print_progress==0:\n",
    "                sys.stderr.write('\\rEpoch: %d/%d' % (i+1, self.epochs))\n",
    "                sys.stderr.flush()\n",
    "\n",
    "            if self.shuffle:\n",
    "                idx_shuffle = np.random.permutation(y_data.shape[0])\n",
    "                X_data, Y_enc, y_data = X_data[idx_shuffle], Y_enc[:, idx_shuffle], y_data[idx_shuffle]\n",
    "\n",
    "            mini = np.array_split(range(y_data.shape[0]), self.minibatches)\n",
    "            mini_cost = []\n",
    "            for idx in mini:\n",
    "\n",
    "                # feedforward\n",
    "                A1, Z1, A2, Z2, A3 = self._feedforward(X_data[idx],\n",
    "                                                       self.W1,\n",
    "                                                       self.W2)\n",
    "                \n",
    "                cost = self._cost(A3,Y_enc[:, idx],self.W1,self.W2)\n",
    "                mini_cost.append(cost) # this appends cost of mini-batch only\n",
    "\n",
    "                # compute gradient via backpropagation\n",
    "                grad1, grad2 = self._get_gradient(A1=A1, A2=A2, A3=A3, Z1=Z1, Z2=Z2, \n",
    "                                                  Y_enc=Y_enc[:, idx],\n",
    "                                                  W1=self.W1,W2=self.W2)\n",
    "\n",
    "                delta_W1, delta_W2 = self.eta * grad1, self.eta * grad2\n",
    "                self.W1 -= (delta_W1 + (self.alpha * delta_W1_prev))\n",
    "                self.W2 -= (delta_W2 + (self.alpha * delta_W2_prev))\n",
    "                delta_W1_prev, delta_W2_prev = delta_W1, delta_W2\n",
    "\n",
    "            self.cost_.append(mini_cost)\n",
    "            self.score_.append(accuracy_score(y_data,self.predict(X_data)))\n",
    "            \n",
    "        return self\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to implement the new style of objective function, \n",
    "# we just need to update the final layer calculation of the gradient\n",
    "class TLPMiniBatchCrossEntropy(TLPMiniBatch):\n",
    "    def _cost(self,A3,Y_enc,W1,W2):\n",
    "        '''Get the objective function value'''\n",
    "        cost = -np.mean(np.nan_to_num((Y_enc*np.log(A3)+(1-Y_enc)*np.log(1-A3))))\n",
    "        L2_term = self._L2_reg(self.l2_C, W1, W2)\n",
    "        return cost + L2_term\n",
    "    \n",
    "    def _get_gradient(self, A1, A2, A3, Z1, Z2, Y_enc, W1, W2):\n",
    "        \"\"\" Compute gradient step using backpropagation.\n",
    "        \"\"\"\n",
    "        # vectorized backpropagation\n",
    "        sigma3 = (A3-Y_enc) # <- this is only line that changed\n",
    "        if(self.nonlinearity == \"sigmoid\"):\n",
    "            sigma2 = (W2.T @ sigma3)*A2*(1-A2)\n",
    "        else:\n",
    "            sigma2 = (W2.T @ sigma3)\n",
    "        grad1 = sigma2[1:,:] @ A1\n",
    "        grad2 = sigma3 @ A2.T\n",
    "        \n",
    "        # regularize weights that are not bias terms\n",
    "        grad1[:, 1:] += W1[:, 1:] * self.l2_C\n",
    "        grad2[:, 1:] += W2[:, 1:] * self.l2_C\n",
    "\n",
    "        return grad1, grad2\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TLPDropoutQuad(TLPMiniBatch):\n",
    "    def __init__(self, dropout=True, **kwds):        \n",
    "        # need to add to the original initializer \n",
    "        self.dropout = dropout\n",
    "\n",
    "        # but keep other keywords\n",
    "        super().__init__(**kwds)\n",
    "        \n",
    "    def fit(self, X, y, print_progress=0, XY_test=None):\n",
    "        \"\"\" Learn weights from training data. With mini-batch\"\"\"\n",
    "        X_data, y_data = X.copy(), y.copy()\n",
    "        Y_enc = self._encode_labels(y)\n",
    "        \n",
    "        # init weights and setup matrices\n",
    "        self.n_features_ = X_data.shape[1]\n",
    "        self.n_output_ = Y_enc.shape[0]\n",
    "        self.W1, self.W2 = self._initialize_weights()\n",
    "\n",
    "        delta_W1_prev = np.zeros(self.W1.shape)\n",
    "        delta_W2_prev = np.zeros(self.W2.shape)\n",
    "\n",
    "        self.cost_ = []\n",
    "        self.score_ = []\n",
    "        if XY_test is not None:\n",
    "            X_test = XY_test[0].copy()\n",
    "            y_test = XY_test[1].copy()\n",
    "            self.val_score_ = []\n",
    "        for i in range(self.epochs):\n",
    "\n",
    "            # adaptive learning rate\n",
    "            self.eta /= (1 + self.decrease_const*i)\n",
    "\n",
    "            if print_progress>0 and (i+1)%print_progress==0:\n",
    "                sys.stderr.write('\\rEpoch: %d/%d' % (i+1, self.epochs))\n",
    "                sys.stderr.flush()\n",
    "\n",
    "            if self.shuffle:\n",
    "                idx_shuffle = np.random.permutation(y_data.shape[0])\n",
    "                X_data, Y_enc, y_data = X_data[idx_shuffle], Y_enc[:, idx_shuffle], y_data[idx_shuffle]\n",
    "\n",
    "            mini = np.array_split(range(y_data.shape[0]), self.minibatches)\n",
    "            mini_cost = []\n",
    "            \n",
    "            # adding dropout neurons\n",
    "            W1 = self.W1.copy()\n",
    "            W2 = self.W2.copy()\n",
    "            \n",
    "            if self.dropout:\n",
    "                # be sure to select the other half of the neurons each epoch\n",
    "                if True :#i%2 == 0:\n",
    "                    # randomly select half of the neurons\n",
    "                    idx_dropout = np.random.permutation(W1.shape[0])\n",
    "                    idx_other_half = idx_dropout[:int(W1.shape[0]/2)]\n",
    "                    idx_dropout = idx_dropout[int(W1.shape[0]/2):] #drop half\n",
    "                else:\n",
    "                    # select the other half\n",
    "                    idx_dropout = idx_other_half\n",
    "                    \n",
    "                idx_dropout = np.sort(idx_dropout)\n",
    "                idx_W2_withbias = np.hstack(([0],(idx_dropout+1)))\n",
    "                W1 = W1[idx_dropout,:]# get rid of rows\n",
    "                W2 = W2[:,idx_W2_withbias]# get rid of extra columns\n",
    "                delta_W1_prev_dropout = delta_W1_prev[idx_dropout,:]\n",
    "                delta_W2_prev_dropout = delta_W2_prev[:,idx_W2_withbias]\n",
    "            else:\n",
    "                delta_W1_prev_dropout = delta_W1_prev\n",
    "                delta_W2_prev_dropout = delta_W2_prev\n",
    "                \n",
    "            \n",
    "            for idx in mini:\n",
    "\n",
    "                # feedforward\n",
    "                A1, Z1, A2, Z2, A3 = self._feedforward(X_data[idx],\n",
    "                                                       W1,\n",
    "                                                       W2)\n",
    "                \n",
    "                cost = self._cost(A3,Y_enc[:, idx],W1,W2)\n",
    "                mini_cost.append(cost) # this appends cost of mini-batch only\n",
    "\n",
    "                # compute gradient via backpropagation\n",
    "                grad1, grad2 = self._get_gradient(A1=A1, A2=A2, A3=A3, Z1=Z1, Z2=Z2,\n",
    "                                                  Y_enc=Y_enc[:, idx],\n",
    "                                                  W1=W1,W2=W2)\n",
    "\n",
    "                delta_W1, delta_W2 = self.eta * grad1, self.eta * grad2\n",
    "                W1 -= (delta_W1 + (self.alpha * delta_W1_prev_dropout))\n",
    "                W2 -= (delta_W2 + (self.alpha * delta_W2_prev_dropout))\n",
    "                delta_W1_prev_dropout, delta_W2_prev_dropout = delta_W1, delta_W2\n",
    "\n",
    "            if self.dropout:\n",
    "                # now append the learned weights back into the original matrices\n",
    "                self.W1[idx_dropout,:] = W1\n",
    "                self.W2[:,idx_W2_withbias] = W2\n",
    "                delta_W1_prev[idx_dropout,:] = delta_W1_prev_dropout\n",
    "                delta_W2_prev[:,idx_W2_withbias] = delta_W2_prev_dropout\n",
    "            else:\n",
    "                # don't eliminate any neurons\n",
    "                self.W1 = W1\n",
    "                self.W2 = W2\n",
    "                delta_W1_prev = delta_W1_prev_dropout\n",
    "                delta_W2_prev = delta_W2_prev_dropout\n",
    "                \n",
    "            self.score_.append(accuracy_score(y_data,self.predict(X_data)))\n",
    "            self.cost_.append(mini_cost) # only uses dropped samples, so more noise\n",
    "            if XY_test is not None:\n",
    "                self.val_score_.append(accuracy_score(y_test,self.predict(X_test)))\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class TLPDropout(TLPMiniBatchCrossEntropy):\n",
    "    def __init__(self, dropout=True, **kwds):        \n",
    "        # need to add to the original initializer \n",
    "        self.dropout = dropout\n",
    "\n",
    "        # but keep other keywords\n",
    "        super().__init__(**kwds)\n",
    "        \n",
    "    def fit(self, X, y, print_progress=0, XY_test=None):\n",
    "        \"\"\" Learn weights from training data. With mini-batch\"\"\"\n",
    "        X_data, y_data = X.copy(), y.copy()\n",
    "        Y_enc = self._encode_labels(y)\n",
    "        \n",
    "        # init weights and setup matrices\n",
    "        self.n_features_ = X_data.shape[1]\n",
    "        self.n_output_ = Y_enc.shape[0]\n",
    "        self.W1, self.W2 = self._initialize_weights()\n",
    "\n",
    "        delta_W1_prev = np.zeros(self.W1.shape)\n",
    "        delta_W2_prev = np.zeros(self.W2.shape)\n",
    "\n",
    "        self.cost_ = []\n",
    "        self.score_ = []\n",
    "        if XY_test is not None:\n",
    "            X_test = XY_test[0].copy()\n",
    "            y_test = XY_test[1].copy()\n",
    "            self.val_score_ = []\n",
    "        for i in range(self.epochs):\n",
    "\n",
    "            # adaptive learning rate\n",
    "            self.eta /= (1 + self.decrease_const*i)\n",
    "\n",
    "            if print_progress>0 and (i+1)%print_progress==0:\n",
    "                sys.stderr.write('\\rEpoch: %d/%d' % (i+1, self.epochs))\n",
    "                sys.stderr.flush()\n",
    "\n",
    "            if self.shuffle:\n",
    "                idx_shuffle = np.random.permutation(y_data.shape[0])\n",
    "                X_data, Y_enc, y_data = X_data[idx_shuffle], Y_enc[:, idx_shuffle], y_data[idx_shuffle]\n",
    "\n",
    "            mini = np.array_split(range(y_data.shape[0]), self.minibatches)\n",
    "            mini_cost = []\n",
    "            \n",
    "            # adding dropout neurons\n",
    "            W1 = self.W1.copy()\n",
    "            W2 = self.W2.copy()\n",
    "            \n",
    "            if self.dropout:\n",
    "                # be sure to select the other half of the neurons each epoch\n",
    "                if True :#i%2 == 0:\n",
    "                    # randomly select half of the neurons\n",
    "                    idx_dropout = np.random.permutation(W1.shape[0])\n",
    "                    idx_other_half = idx_dropout[:int(W1.shape[0]/2)]\n",
    "                    idx_dropout = idx_dropout[int(W1.shape[0]/2):] #drop half\n",
    "                else:\n",
    "                    # select the other half\n",
    "                    idx_dropout = idx_other_half\n",
    "                    \n",
    "                idx_dropout = np.sort(idx_dropout)\n",
    "                idx_W2_withbias = np.hstack(([0],(idx_dropout+1)))\n",
    "                W1 = W1[idx_dropout,:]# get rid of rows\n",
    "                W2 = W2[:,idx_W2_withbias]# get rid of extra columns\n",
    "                delta_W1_prev_dropout = delta_W1_prev[idx_dropout,:]\n",
    "                delta_W2_prev_dropout = delta_W2_prev[:,idx_W2_withbias]\n",
    "            else:\n",
    "                delta_W1_prev_dropout = delta_W1_prev\n",
    "                delta_W2_prev_dropout = delta_W2_prev\n",
    "                \n",
    "            \n",
    "            for idx in mini:\n",
    "\n",
    "                # feedforward\n",
    "                A1, Z1, A2, Z2, A3 = self._feedforward(X_data[idx],\n",
    "                                                       W1,\n",
    "                                                       W2)\n",
    "                \n",
    "                cost = self._cost(A3,Y_enc[:, idx],W1,W2)\n",
    "                mini_cost.append(cost) # this appends cost of mini-batch only\n",
    "\n",
    "                # compute gradient via backpropagation\n",
    "                grad1, grad2 = self._get_gradient(A1=A1, A2=A2, A3=A3, Z1=Z1, Z2=Z2,\n",
    "                                                  Y_enc=Y_enc[:, idx],\n",
    "                                                  W1=W1,W2=W2)\n",
    "\n",
    "                delta_W1, delta_W2 = self.eta * grad1, self.eta * grad2\n",
    "                W1 -= (delta_W1 + (self.alpha * delta_W1_prev_dropout))\n",
    "                W2 -= (delta_W2 + (self.alpha * delta_W2_prev_dropout))\n",
    "                delta_W1_prev_dropout, delta_W2_prev_dropout = delta_W1, delta_W2\n",
    "\n",
    "            if self.dropout:\n",
    "                # now append the learned weights back into the original matrices\n",
    "                self.W1[idx_dropout,:] = W1\n",
    "                self.W2[:,idx_W2_withbias] = W2\n",
    "                delta_W1_prev[idx_dropout,:] = delta_W1_prev_dropout\n",
    "                delta_W2_prev[:,idx_W2_withbias] = delta_W2_prev_dropout\n",
    "            else:\n",
    "                # don't eliminate any neurons\n",
    "                self.W1 = W1\n",
    "                self.W2 = W2\n",
    "                delta_W1_prev = delta_W1_prev_dropout\n",
    "                delta_W2_prev = delta_W2_prev_dropout\n",
    "                \n",
    "            self.score_.append(accuracy_score(y_data,self.predict(X_data)))\n",
    "            self.cost_.append(mini_cost) # only uses dropped samples, so more noise\n",
    "            if XY_test is not None:\n",
    "                self.val_score_.append(accuracy_score(y_test,self.predict(X_test)))\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TLPGaussianInitialQuad(TLPMiniBatch):             \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize weights with smal l random numbers.\"\"\"\n",
    "        W1 = np.random.randn(self.n_hidden, self.n_features_ + 1)\n",
    "        W1[:,1:] = W1[:,1:]/np.sqrt(self.n_features_+1) # don't saturate the neuron\n",
    "        \n",
    "        W2 = np.random.randn(self.n_output_, self.n_hidden + 1)\n",
    "        W2[:,1:] = W2[:,1:]/np.sqrt(self.n_hidden+1) # don't saturate the neuron\n",
    "        return W1, W2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TLPGaussianInitial(TLPMiniBatchCrossEntropy):             \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize weights with small random numbers.\"\"\"\n",
    "        W1 = np.random.randn(self.n_hidden, self.n_features_ + 1)\n",
    "        W1[:,1:] = W1[:,1:]/np.sqrt(self.n_features_+1) # don't saturate the neuron\n",
    "        \n",
    "        W2 = np.random.randn(self.n_output_, self.n_hidden + 1)\n",
    "        W2[:,1:] = W2[:,1:]/np.sqrt(self.n_hidden+1) # don't saturate the neuron\n",
    "        return W1, W2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vals = {'n_hidden':50, \n",
    "         'C':1e-2, 'epochs':75, 'eta':0.001, \n",
    "         'alpha':0.0, 'decrease_const':1e-9, 'minibatches':200,\n",
    "         'shuffle':True,'random_state':1, 'dropout':False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TLPReLu(TLPDropout):\n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize weights with small random numbers.\"\"\"\n",
    "        # suggested relu/sigmoid bounds\n",
    "        # Glorot, Xavier, Antoine Bordes, and Yoshua Bengio. \n",
    "        #   \"Deep Sparse Rectifier Neural Networks.\"\n",
    "        init_bound = np.sqrt(6. / (self.n_hidden + self.n_features_ + 1))\n",
    "        W1 = np.random.uniform(-init_bound, init_bound,(self.n_hidden, self.n_features_ + 1))\n",
    "\n",
    "        init_bound = np.sqrt(2. / (self.n_output_ + self.n_hidden + 1))\n",
    "        W2 = np.random.uniform(-init_bound, init_bound,(self.n_output_, self.n_hidden + 1))\n",
    "        return W1, W2\n",
    "    \n",
    "    @staticmethod\n",
    "    def _relu(Z):\n",
    "        return np.maximum(0,Z.copy())\n",
    "        \n",
    "    def _feedforward(self, X, W1, W2):\n",
    "        \"\"\"Compute feedforward step\n",
    "        \"\"\"\n",
    "        # A1->W1->ReLu->A2->W2->Sigmoid\n",
    "        A1 = self._add_bias_unit(X, how='column')\n",
    "        Z1 = W1 @ A1.T\n",
    "        A2 = self._relu(Z1)\n",
    "        A2 = self._add_bias_unit(A2, how='row')\n",
    "        Z2 = W2 @ A2\n",
    "        A3 = self._sigmoid(Z2)\n",
    "        return A1, Z1, A2, Z2, A3\n",
    "    \n",
    "    def _get_gradient(self, A1, A2, A3, Z1, Z2, Y_enc, W1, W2):\n",
    "        \"\"\" Compute gradient step using backpropagation.\n",
    "        \"\"\"\n",
    "        # vectorized backpropagation\n",
    "        sigma3 = (A3-Y_enc) \n",
    "        # sigma3[Z2<=0] = 0 # can change to be relu back prop on this layer too!\n",
    "        \n",
    "        sigma2 = (W2.T @ sigma3) \n",
    "        Z1_with_bias = self._add_bias_unit(Z1,how='row')\n",
    "        sigma2[Z1_with_bias<=0] = 0\n",
    "        # relu derivative only zeros out certain values! easy!\n",
    "        \n",
    "        grad1 = sigma2[1:,:] @ A1\n",
    "        grad2 = sigma3 @ A2.T\n",
    "        \n",
    "        # regularize weights that are not bias terms\n",
    "        grad1[:, 1:] += (W1[:, 1:] * self.l2_C)\n",
    "        grad2[:, 1:] += (W2[:, 1:] * self.l2_C)\n",
    "\n",
    "        return grad1, grad2\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "def print_result(nn,X_train,y_train,X_test,y_test,title=\"\",color=\"red\"):\n",
    "    \n",
    "    print(\"=================\")\n",
    "    print(title,\":\")\n",
    "    yhat = nn.predict(X_train)\n",
    "    print('Resubstitution acc:',accuracy_score(y_train,yhat))\n",
    "    \n",
    "    yhat = nn.predict(X_test)\n",
    "    print('Validation acc:',accuracy_score(y_test,yhat))\n",
    "    \n",
    "    if hasattr(nn,'val_score_'):\n",
    "        plt.plot(range(len(nn.val_score_)), nn.val_score_, color=color,label=title)\n",
    "        plt.ylabel('Validation Accuracy')\n",
    "    else:\n",
    "        plt.plot(range(len(nn.score_)), nn.score_, color=color,label=title)\n",
    "        plt.ylabel('Resub Accuracy')\n",
    "        \n",
    "    plt.xlabel('Epochs')\n",
    "    plt.tight_layout()\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***\n",
      "quadratic\n",
      "sigmoid\n",
      "***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.59 s, sys: 104 ms, total: 3.7 s\n",
      "Wall time: 980 ms\n",
      "confusion matrix\n",
      " [[ 0  0 14  0  0]\n",
      " [ 0  0 18  0  0]\n",
      " [ 0  0 24  1  0]\n",
      " [ 0  0 23  1  0]\n",
      " [ 0  0 18  4  0]]\n",
      "Weighted Confusion Matrix Score:  739\n",
      "***\n",
      "quadratic\n",
      "sigmoid\n",
      "***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.41 s, sys: 104 ms, total: 3.51 s\n",
      "Wall time: 902 ms\n",
      "confusion matrix\n",
      " [[ 0  0 12  2  0]\n",
      " [ 0  0 15  3  0]\n",
      " [ 0  0 21  4  0]\n",
      " [ 0  0 15  9  0]\n",
      " [ 0  0 13  9  0]]\n",
      "Weighted Confusion Matrix Score:  802\n",
      "***\n",
      "quadratic\n",
      "sigmoid\n",
      "***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 5/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.15 s, sys: 65.2 ms, total: 3.22 s\n",
      "Wall time: 819 ms\n",
      "confusion matrix\n",
      " [[ 0  0 13  0  0]\n",
      " [ 0  0 18  0  0]\n",
      " [ 0  0 25  0  0]\n",
      " [ 0  0 24  0  0]\n",
      " [ 0  0 22  0  0]]\n",
      "Weighted Confusion Matrix Score:  714\n",
      "***\n",
      "quadratic\n",
      "sigmoid\n",
      "***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 5/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.08 s, sys: 72.8 ms, total: 3.15 s\n",
      "Wall time: 802 ms\n",
      "confusion matrix\n",
      " [[ 0  0 13  0  0]\n",
      " [ 0  0 17  1  0]\n",
      " [ 0  0 22  2  0]\n",
      " [ 0  0 22  2  0]\n",
      " [ 0  0 19  3  0]]\n",
      "Weighted Confusion Matrix Score:  731\n",
      "***\n",
      "quadratic\n",
      "sigmoid\n",
      "***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.95 s, sys: 58.9 ms, total: 3.01 s\n",
      "Wall time: 762 ms\n",
      "confusion matrix\n",
      " [[ 0  0 13  0  0]\n",
      " [ 0  0 17  1  0]\n",
      " [ 0  0 23  1  0]\n",
      " [ 0  1 20  3  0]\n",
      " [ 0  0 17  5  0]]\n",
      "Weighted Confusion Matrix Score:  737\n",
      "***\n",
      "quadratic\n",
      "sigmoid\n",
      "***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 5/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.15 s, sys: 59.2 ms, total: 3.21 s\n",
      "Wall time: 817 ms\n",
      "confusion matrix\n",
      " [[ 0  0 13  0  0]\n",
      " [ 0  0 18  0  0]\n",
      " [ 0  0 24  0  0]\n",
      " [ 0  0 24  0  0]\n",
      " [ 0  0 22  0  0]]\n",
      "Weighted Confusion Matrix Score:  707\n",
      "***\n",
      "quadratic\n",
      "sigmoid\n",
      "***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.99 s, sys: 72.2 ms, total: 3.06 s\n",
      "Wall time: 778 ms\n",
      "confusion matrix\n",
      " [[ 0  0 13  0  0]\n",
      " [ 0  0 17  0  0]\n",
      " [ 0  0 24  0  0]\n",
      " [ 0  0 23  1  0]\n",
      " [ 0  0 18  4  0]]\n",
      "Weighted Confusion Matrix Score:  715\n",
      "***\n",
      "quadratic\n",
      "sigmoid\n",
      "***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.15 s, sys: 78.8 ms, total: 3.22 s\n",
      "Wall time: 820 ms\n",
      "confusion matrix\n",
      " [[ 0  0 13  0  0]\n",
      " [ 0  0 17  0  0]\n",
      " [ 0  0 24  0  0]\n",
      " [ 0  0 23  1  0]\n",
      " [ 0  0 20  2  0]]\n",
      "Weighted Confusion Matrix Score:  709\n",
      "***\n",
      "quadratic\n",
      "sigmoid\n",
      "***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.97 s, sys: 43.5 ms, total: 3.02 s\n",
      "Wall time: 758 ms\n",
      "confusion matrix\n",
      " [[ 0  0  2  8  3]\n",
      " [ 0  0  5  9  3]\n",
      " [ 0  0  2 17  5]\n",
      " [ 0  0  2 17  4]\n",
      " [ 0  0  2 18  2]]\n",
      "Weighted Confusion Matrix Score:  1036\n",
      "***\n",
      "quadratic\n",
      "sigmoid\n",
      "***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/15/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:62: RuntimeWarning: overflow encountered in square\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:61: RuntimeWarning: invalid value encountered in multiply\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:62: RuntimeWarning: invalid value encountered in multiply\n",
      "Epoch: 4/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.05 s, sys: 69.4 ms, total: 3.12 s\n",
      "Wall time: 791 ms\n",
      "confusion matrix\n",
      " [[ 0  0  6  7  0]\n",
      " [ 0  0 14  3  0]\n",
      " [ 0  0  4 20  0]\n",
      " [ 0  0  6 17  0]\n",
      " [ 0  0  6 15  0]]\n",
      "Weighted Confusion Matrix Score:  872\n",
      "***\n",
      "quadratic\n",
      "linear\n",
      "***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/15/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:62: RuntimeWarning: overflow encountered in square\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:61: RuntimeWarning: invalid value encountered in multiply\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:62: RuntimeWarning: invalid value encountered in multiply\n",
      "Epoch: 5/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.91 s, sys: 75.9 ms, total: 2.99 s\n",
      "Wall time: 763 ms\n",
      "confusion matrix\n",
      " [[14  0  0  0  0]\n",
      " [18  0  0  0  0]\n",
      " [25  0  0  0  0]\n",
      " [24  0  0  0  0]\n",
      " [22  0  0  0  0]]\n",
      "Weighted Confusion Matrix Score:  1030\n",
      "***\n",
      "quadratic\n",
      "linear\n",
      "***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/15/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:62: RuntimeWarning: overflow encountered in square\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:61: RuntimeWarning: invalid value encountered in multiply\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:62: RuntimeWarning: invalid value encountered in multiply\n",
      "Epoch: 5/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.74 s, sys: 44.9 ms, total: 2.78 s\n",
      "Wall time: 699 ms\n",
      "confusion matrix\n",
      " [[14  0  0  0  0]\n",
      " [18  0  0  0  0]\n",
      " [25  0  0  0  0]\n",
      " [24  0  0  0  0]\n",
      " [22  0  0  0  0]]\n",
      "Weighted Confusion Matrix Score:  1030\n",
      "***\n",
      "quadratic\n",
      "linear\n",
      "***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/15/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:62: RuntimeWarning: overflow encountered in square\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:61: RuntimeWarning: invalid value encountered in multiply\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:62: RuntimeWarning: invalid value encountered in multiply\n",
      "Epoch: 5/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.86 s, sys: 64.4 ms, total: 2.93 s\n",
      "Wall time: 741 ms\n",
      "confusion matrix\n",
      " [[13  0  0  0  0]\n",
      " [18  0  0  0  0]\n",
      " [25  0  0  0  0]\n",
      " [24  0  0  0  0]\n",
      " [22  0  0  0  0]]\n",
      "Weighted Confusion Matrix Score:  1020\n",
      "***\n",
      "quadratic\n",
      "linear\n",
      "***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/15/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:62: RuntimeWarning: overflow encountered in square\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:61: RuntimeWarning: invalid value encountered in multiply\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:62: RuntimeWarning: invalid value encountered in multiply\n",
      "Epoch: 4/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.68 s, sys: 48.2 ms, total: 2.72 s\n",
      "Wall time: 686 ms\n",
      "confusion matrix\n",
      " [[13  0  0  0  0]\n",
      " [18  0  0  0  0]\n",
      " [24  0  0  0  0]\n",
      " [24  0  0  0  0]\n",
      " [22  0  0  0  0]]\n",
      "Weighted Confusion Matrix Score:  1010\n",
      "***\n",
      "quadratic\n",
      "linear\n",
      "***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/15/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:62: RuntimeWarning: overflow encountered in square\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:62: RuntimeWarning: invalid value encountered in multiply\n",
      "Epoch: 5/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.87 s, sys: 55.1 ms, total: 2.92 s\n",
      "Wall time: 739 ms\n",
      "confusion matrix\n",
      " [[13  0  0  0  0]\n",
      " [18  0  0  0  0]\n",
      " [24  0  0  0  0]\n",
      " [24  0  0  0  0]\n",
      " [22  0  0  0  0]]\n",
      "Weighted Confusion Matrix Score:  1010\n",
      "***\n",
      "quadratic\n",
      "linear\n",
      "***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/15/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:62: RuntimeWarning: overflow encountered in square\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:61: RuntimeWarning: invalid value encountered in multiply\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:62: RuntimeWarning: invalid value encountered in multiply\n",
      "Epoch: 5/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.88 s, sys: 74.1 ms, total: 2.96 s\n",
      "Wall time: 752 ms\n",
      "confusion matrix\n",
      " [[13  0  0  0  0]\n",
      " [18  0  0  0  0]\n",
      " [24  0  0  0  0]\n",
      " [24  0  0  0  0]\n",
      " [22  0  0  0  0]]\n",
      "Weighted Confusion Matrix Score:  1010\n",
      "***\n",
      "quadratic\n",
      "linear\n",
      "***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/15/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:62: RuntimeWarning: overflow encountered in square\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:62: RuntimeWarning: invalid value encountered in multiply\n",
      "Epoch: 4/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.82 s, sys: 62.8 ms, total: 2.89 s\n",
      "Wall time: 730 ms\n",
      "confusion matrix\n",
      " [[13  0  0  0  0]\n",
      " [17  0  0  0  0]\n",
      " [24  0  0  0  0]\n",
      " [24  0  0  0  0]\n",
      " [22  0  0  0  0]]\n",
      "Weighted Confusion Matrix Score:  1000\n",
      "***\n",
      "quadratic\n",
      "linear\n",
      "***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/15/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:62: RuntimeWarning: overflow encountered in square\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:61: RuntimeWarning: invalid value encountered in multiply\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:62: RuntimeWarning: invalid value encountered in multiply\n",
      "Epoch: 5/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.86 s, sys: 53.4 ms, total: 2.92 s\n",
      "Wall time: 737 ms\n",
      "confusion matrix\n",
      " [[13  0  0  0  0]\n",
      " [17  0  0  0  0]\n",
      " [24  0  0  0  0]\n",
      " [24  0  0  0  0]\n",
      " [22  0  0  0  0]]\n",
      "Weighted Confusion Matrix Score:  1000\n",
      "***\n",
      "quadratic\n",
      "linear\n",
      "***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/15/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:62: RuntimeWarning: overflow encountered in square\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:61: RuntimeWarning: invalid value encountered in multiply\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:62: RuntimeWarning: invalid value encountered in multiply\n",
      "Epoch: 4/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.8 s, sys: 63.5 ms, total: 2.86 s\n",
      "Wall time: 724 ms\n",
      "confusion matrix\n",
      " [[13  0  0  0  0]\n",
      " [17  0  0  0  0]\n",
      " [24  0  0  0  0]\n",
      " [23  0  0  0  0]\n",
      " [22  0  0  0  0]]\n",
      "Weighted Confusion Matrix Score:  990\n",
      "***\n",
      "quadratic\n",
      "linear\n",
      "***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.89 s, sys: 73.3 ms, total: 2.96 s\n",
      "Wall time: 753 ms\n",
      "confusion matrix\n",
      " [[13  0  0  0  0]\n",
      " [17  0  0  0  0]\n",
      " [24  0  0  0  0]\n",
      " [23  0  0  0  0]\n",
      " [21  0  0  0  0]]\n",
      "Weighted Confusion Matrix Score:  980\n",
      "***\n",
      "cross\n",
      "sigmoid\n",
      "***\n",
      "in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.58 s, sys: 65.5 ms, total: 3.64 s\n",
      "Wall time: 918 ms\n",
      "confusion matrix\n",
      " [[ 0  0 14  0  0]\n",
      " [ 0  0 18  0  0]\n",
      " [ 0  0 25  0  0]\n",
      " [ 0  0 24  0  0]\n",
      " [ 0  0 22  0  0]]\n",
      "Weighted Confusion Matrix Score:  721\n",
      "***\n",
      "cross\n",
      "sigmoid\n",
      "***\n",
      "in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.42 s, sys: 64.4 ms, total: 3.49 s\n",
      "Wall time: 881 ms\n",
      "confusion matrix\n",
      " [[ 0  0 14  0  0]\n",
      " [ 0  0 18  0  0]\n",
      " [ 0  0 25  0  0]\n",
      " [ 0  0 24  0  0]\n",
      " [ 0  0 22  0  0]]\n",
      "Weighted Confusion Matrix Score:  721\n",
      "***\n",
      "cross\n",
      "sigmoid\n",
      "***\n",
      "in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.32 s, sys: 47.3 ms, total: 3.37 s\n",
      "Wall time: 883 ms\n",
      "confusion matrix\n",
      " [[ 0  0  2  0 11]\n",
      " [ 0  0  2  0 16]\n",
      " [ 0  0  2  0 23]\n",
      " [ 0  0  1  0 23]\n",
      " [ 0  0  2  0 20]]\n",
      "Weighted Confusion Matrix Score:  1458\n",
      "***\n",
      "cross\n",
      "sigmoid\n",
      "***\n",
      "in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.29 s, sys: 59.3 ms, total: 3.35 s\n",
      "Wall time: 846 ms\n",
      "confusion matrix\n",
      " [[ 0  0 12  1  0]\n",
      " [ 0  0 16  2  0]\n",
      " [ 0  0 19  5  0]\n",
      " [ 0  0 13 11  0]\n",
      " [ 0  0 12 10  0]]\n",
      "Weighted Confusion Matrix Score:  794\n",
      "***\n",
      "cross\n",
      "sigmoid\n",
      "***\n",
      "in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.45 s, sys: 69.3 ms, total: 3.52 s\n",
      "Wall time: 890 ms\n",
      "confusion matrix\n",
      " [[ 0  0 13  0  0]\n",
      " [ 0  0 18  0  0]\n",
      " [ 0  0 22  2  0]\n",
      " [ 0  0 24  0  0]\n",
      " [ 0  0 19  3  0]]\n",
      "Weighted Confusion Matrix Score:  722\n",
      "***\n",
      "cross\n",
      "sigmoid\n",
      "***\n",
      "in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.54 s, sys: 70 ms, total: 3.61 s\n",
      "Wall time: 914 ms\n",
      "confusion matrix\n",
      " [[ 0  0 12  1  0]\n",
      " [ 0  0 16  2  0]\n",
      " [ 0  0 13 11  0]\n",
      " [ 0  1 14  9  0]\n",
      " [ 0  0  8 14  0]]\n",
      "Weighted Confusion Matrix Score:  818\n",
      "***\n",
      "cross\n",
      "sigmoid\n",
      "***\n",
      "in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.65 s, sys: 92.1 ms, total: 3.75 s\n",
      "Wall time: 953 ms\n",
      "confusion matrix\n",
      " [[ 0  0 12  0  1]\n",
      " [ 0  0 12  0  5]\n",
      " [ 0  0 16  0  8]\n",
      " [ 0  0 13  0 11]\n",
      " [ 0  0  6  0 16]]\n",
      "Weighted Confusion Matrix Score:  1028\n",
      "***\n",
      "cross\n",
      "sigmoid\n",
      "***\n",
      "in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.45 s, sys: 66.9 ms, total: 3.52 s\n",
      "Wall time: 890 ms\n",
      "confusion matrix\n",
      " [[ 0  0  9  4  0]\n",
      " [ 0  0 12  5  0]\n",
      " [ 0  0 13 11  0]\n",
      " [ 0  0  9 15  0]\n",
      " [ 0  0  6 16  0]]\n",
      "Weighted Confusion Matrix Score:  853\n",
      "***\n",
      "cross\n",
      "sigmoid\n",
      "***\n",
      "in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.42 s, sys: 78.9 ms, total: 3.5 s\n",
      "Wall time: 888 ms\n",
      "confusion matrix\n",
      " [[ 0  0  0  0 13]\n",
      " [ 0  0  0  0 17]\n",
      " [ 0  0  2  0 22]\n",
      " [ 0  0  0  0 23]\n",
      " [ 0  0  0  0 22]]\n",
      "Weighted Confusion Matrix Score:  1469\n",
      "***\n",
      "cross\n",
      "sigmoid\n",
      "***\n",
      "in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/15/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:6: RuntimeWarning: invalid value encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:61: RuntimeWarning: invalid value encountered in multiply\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:62: RuntimeWarning: invalid value encountered in multiply\n",
      "Epoch: 4/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.41 s, sys: 60.9 ms, total: 3.47 s\n",
      "Wall time: 879 ms\n",
      "confusion matrix\n",
      " [[ 0  0 13  0  0]\n",
      " [ 0  0 17  0  0]\n",
      " [ 0  0 24  0  0]\n",
      " [ 0  0 22  1  0]\n",
      " [ 0  0 21  0  0]]\n",
      "Weighted Confusion Matrix Score:  689\n",
      "***\n",
      "cross\n",
      "linear\n",
      "***\n",
      "in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/15/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:6: RuntimeWarning: invalid value encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:61: RuntimeWarning: invalid value encountered in multiply\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:62: RuntimeWarning: invalid value encountered in multiply\n",
      "Epoch: 4/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.53 s, sys: 84.9 ms, total: 3.61 s\n",
      "Wall time: 919 ms\n",
      "confusion matrix\n",
      " [[14  0  0  0  0]\n",
      " [18  0  0  0  0]\n",
      " [25  0  0  0  0]\n",
      " [24  0  0  0  0]\n",
      " [22  0  0  0  0]]\n",
      "Weighted Confusion Matrix Score:  1030\n",
      "***\n",
      "cross\n",
      "linear\n",
      "***\n",
      "in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/15/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:6: RuntimeWarning: invalid value encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:61: RuntimeWarning: invalid value encountered in multiply\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:62: RuntimeWarning: invalid value encountered in multiply\n",
      "Epoch: 4/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.25 s, sys: 62.4 ms, total: 3.32 s\n",
      "Wall time: 839 ms\n",
      "confusion matrix\n",
      " [[14  0  0  0  0]\n",
      " [18  0  0  0  0]\n",
      " [25  0  0  0  0]\n",
      " [24  0  0  0  0]\n",
      " [22  0  0  0  0]]\n",
      "Weighted Confusion Matrix Score:  1030\n",
      "***\n",
      "cross\n",
      "linear\n",
      "***\n",
      "in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/15/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:6: RuntimeWarning: invalid value encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:61: RuntimeWarning: invalid value encountered in multiply\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:62: RuntimeWarning: invalid value encountered in multiply\n",
      "Epoch: 4/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.19 s, sys: 48.9 ms, total: 3.24 s\n",
      "Wall time: 815 ms\n",
      "confusion matrix\n",
      " [[13  0  0  0  0]\n",
      " [18  0  0  0  0]\n",
      " [25  0  0  0  0]\n",
      " [24  0  0  0  0]\n",
      " [22  0  0  0  0]]\n",
      "Weighted Confusion Matrix Score:  1020\n",
      "***\n",
      "cross\n",
      "linear\n",
      "***\n",
      "in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/15/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:6: RuntimeWarning: invalid value encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:61: RuntimeWarning: invalid value encountered in multiply\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:62: RuntimeWarning: invalid value encountered in multiply\n",
      "Epoch: 4/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.29 s, sys: 79.4 ms, total: 3.37 s\n",
      "Wall time: 857 ms\n",
      "confusion matrix\n",
      " [[13  0  0  0  0]\n",
      " [18  0  0  0  0]\n",
      " [24  0  0  0  0]\n",
      " [24  0  0  0  0]\n",
      " [22  0  0  0  0]]\n",
      "Weighted Confusion Matrix Score:  1010\n",
      "***\n",
      "cross\n",
      "linear\n",
      "***\n",
      "in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/15/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:6: RuntimeWarning: invalid value encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:61: RuntimeWarning: invalid value encountered in multiply\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:62: RuntimeWarning: invalid value encountered in multiply\n",
      "Epoch: 4/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.3 s, sys: 83.3 ms, total: 3.38 s\n",
      "Wall time: 860 ms\n",
      "confusion matrix\n",
      " [[13  0  0  0  0]\n",
      " [18  0  0  0  0]\n",
      " [24  0  0  0  0]\n",
      " [24  0  0  0  0]\n",
      " [22  0  0  0  0]]\n",
      "Weighted Confusion Matrix Score:  1010\n",
      "***\n",
      "cross\n",
      "linear\n",
      "***\n",
      "in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/15/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:6: RuntimeWarning: invalid value encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:61: RuntimeWarning: invalid value encountered in multiply\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:62: RuntimeWarning: invalid value encountered in multiply\n",
      "Epoch: 4/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.22 s, sys: 51.2 ms, total: 3.27 s\n",
      "Wall time: 824 ms\n",
      "confusion matrix\n",
      " [[13  0  0  0  0]\n",
      " [18  0  0  0  0]\n",
      " [24  0  0  0  0]\n",
      " [24  0  0  0  0]\n",
      " [22  0  0  0  0]]\n",
      "Weighted Confusion Matrix Score:  1010\n",
      "***\n",
      "cross\n",
      "linear\n",
      "***\n",
      "in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/15/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:6: RuntimeWarning: invalid value encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:61: RuntimeWarning: invalid value encountered in multiply\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:62: RuntimeWarning: invalid value encountered in multiply\n",
      "Epoch: 4/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.19 s, sys: 56.2 ms, total: 3.24 s\n",
      "Wall time: 818 ms\n",
      "confusion matrix\n",
      " [[13  0  0  0  0]\n",
      " [17  0  0  0  0]\n",
      " [24  0  0  0  0]\n",
      " [24  0  0  0  0]\n",
      " [22  0  0  0  0]]\n",
      "Weighted Confusion Matrix Score:  1000\n",
      "***\n",
      "cross\n",
      "linear\n",
      "***\n",
      "in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/15/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:6: RuntimeWarning: invalid value encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:61: RuntimeWarning: invalid value encountered in multiply\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:62: RuntimeWarning: invalid value encountered in multiply\n",
      "Epoch: 4/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.53 s, sys: 114 ms, total: 3.64 s\n",
      "Wall time: 939 ms\n",
      "confusion matrix\n",
      " [[13  0  0  0  0]\n",
      " [17  0  0  0  0]\n",
      " [24  0  0  0  0]\n",
      " [24  0  0  0  0]\n",
      " [22  0  0  0  0]]\n",
      "Weighted Confusion Matrix Score:  1000\n",
      "***\n",
      "cross\n",
      "linear\n",
      "***\n",
      "in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/15/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:6: RuntimeWarning: invalid value encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:61: RuntimeWarning: invalid value encountered in multiply\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:62: RuntimeWarning: invalid value encountered in multiply\n",
      "Epoch: 4/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.58 s, sys: 97.6 ms, total: 3.68 s\n",
      "Wall time: 936 ms\n",
      "confusion matrix\n",
      " [[13  0  0  0  0]\n",
      " [17  0  0  0  0]\n",
      " [24  0  0  0  0]\n",
      " [23  0  0  0  0]\n",
      " [22  0  0  0  0]]\n",
      "Weighted Confusion Matrix Score:  990\n",
      "***\n",
      "cross\n",
      "linear\n",
      "***\n",
      "in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 15/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.57 s, sys: 89.9 ms, total: 3.66 s\n",
      "Wall time: 928 ms\n",
      "confusion matrix\n",
      " [[13  0  0  0  0]\n",
      " [17  0  0  0  0]\n",
      " [24  0  0  0  0]\n",
      " [23  0  0  0  0]\n",
      " [21  0  0  0  0]]\n",
      "Weighted Confusion Matrix Score:  980\n"
     ]
    }
   ],
   "source": [
    "with np.errstate(all='ignore'):\n",
    "\n",
    "    nonlinearities = [\"sigmoid\",\"linear\"]\n",
    "    costs = ['quadratic','cross']\n",
    "    \n",
    "    custom_performances = []\n",
    "for cost in costs:\n",
    "    for nonlinearity in nonlinearities:\n",
    "\n",
    "        vals = {'n_hidden':50, \n",
    "                     'C':1e-2, 'epochs':15, 'eta':0.001, \n",
    "                     'alpha':0.0, 'decrease_const':1e-9, 'minibatches':200,\n",
    "                     'shuffle':True,'random_state':1, \n",
    "                       'nonlinearity': nonlinearity}\n",
    "        for train_indices, test_indices in cv_object.split(X,y): \n",
    "                    print(\"***\")\n",
    "                    print(cost)\n",
    "                    print(nonlinearity)\n",
    "                    print(\"***\")\n",
    "                    # I will create new variables here so that it is more obvious what \n",
    "                    # the code is doing (you can compact this syntax and avoid duplicating memory,\n",
    "                    # but it makes this code less readable)\n",
    "                    X_train = (X[train_indices])\n",
    "                    y_train = y[train_indices]\n",
    "\n",
    "                    X_test = (X[test_indices])\n",
    "                    y_test = y[test_indices]\n",
    "                    \n",
    "                    if(cost == \"quadratic\"):\n",
    "                        nn_long_sigmoid = TLPGaussianInitialQuad(**vals)\n",
    "                    else:\n",
    "                        print(\"in\")\n",
    "                        nn_long_sigmoid = TLPGaussianInitial(**vals)\n",
    "\n",
    "                    #%time nn_long_sigmoid.fit(X_train, y_train, print_progress=1, XY_test=(X_test,y_test))\n",
    "                    %time nn_long_sigmoid.fit(X_train, y_train, print_progress=1)\n",
    "                    y_hat = nn_long_sigmoid.predict(X_test) # get test set precitions\n",
    "\n",
    "                    # now let's get the accuracy and confusion matrix for this iterations of training/testing\n",
    "                    acc = mt.accuracy_score(y_test,y_hat+1)\n",
    "            #         lr_clf_accuracies.append(acc)\n",
    "            #         cost_accuracies.append([acc])\n",
    "\n",
    "                    conf = mt.confusion_matrix(y_test,y_hat+1)\n",
    "        #             print(vals)\n",
    "#                     print_result(nn_long_sigmoid,X_train,y_train,X_test,y_test,title=\"Long Run\",color=\"red\")\n",
    "#                     plt.show()\n",
    "                    print(\"confusion matrix\\n\",conf)\n",
    "                    score = get_confusion_costTot(conf, cost_matrix)\n",
    "                    print(\"Weighted Confusion Matrix Score: \", score)\n",
    "                    custom_performances.append(score)\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning the hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_neurons = np.linspace(150, 200, num=10)\n",
    "hidden_neurons.sort()\n",
    "\n",
    "costs = np.logspace(-3,1, num=10)\n",
    "costs.sort()\n",
    "\n",
    "nonlinearities = [\"sigmoid\",\"linear\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:4: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:7: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nonlinearity': 'sigmoid', 'n_hidden': 150.0, 'C': 0.001}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-32ce19b239c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mparam_grid_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'n_hidden'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhidden_neurons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'C'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcosts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nonlinearity'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mnonlinearities\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mgscv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcv_object\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn_long_sigmoid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mparam_grid_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mconfusion_scorer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrefit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mgscv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtest\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \"\"\"\n\u001b[0;32m--> 945\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                   \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m--> 564\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m           for train, test in cv_iter)\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-6af9468bfcd2>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, print_progress)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_cost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-eb3cdecf82d3>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;34m\"\"\"Predict class labels\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feedforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-eb3cdecf82d3>\u001b[0m in \u001b[0;36m_feedforward\u001b[0;34m(self, X, W1, W2)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mZ1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mW1\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mA1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonlinearity\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mA2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0mA2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_bias_unit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'row'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mZ2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mW2\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mA2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-eb3cdecf82d3>\u001b[0m in \u001b[0;36m_sigmoid\u001b[0;34m(z)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;34m\"\"\"Use scipy.special.expit to avoid overflow\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m# 1.0 / (1.0 + np.exp(-z))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mexpit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with np.errstate(all='ignore'):\n",
    "    param_grid_input = {'n_hidden': hidden_neurons, 'C': costs, 'nonlinearity' : nonlinearities}\n",
    "    gscv = GridSearchCV(cv= cv_object, estimator=nn_long_sigmoid, param_grid= param_grid_input, scoring= confusion_scorer,refit=False)\n",
    "    gscv.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing our MLP Implementation with that of Scikit Learn  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 15/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.86 s, sys: 44.8 ms, total: 2.91 s\n",
      "Wall time: 730 ms\n",
      "confusion matrix\n",
      " [[ 0  0  5  9  0]\n",
      " [ 0  0  7 11  0]\n",
      " [ 0  0  8 17  0]\n",
      " [ 0  0  8 16  0]\n",
      " [ 0  0  5 17  0]]\n",
      "Weighted Confusion Matrix Score:  931\n",
      "SCIKIT*****\n",
      "CPU times: user 72.5 ms, sys: 974 s, total: 73.5 ms\n",
      "Wall time: 18.4 ms\n",
      "Validation Acc: 0.233009708738\n",
      "confusion matrix\n",
      " [[ 0  5  9  0  0]\n",
      " [ 0  7 11  0  0]\n",
      " [ 0  8 17  0  0]\n",
      " [ 0  8 16  0  0]\n",
      " [ 0  5 17  0  0]]\n",
      "Weighted Confusion Matrix Score:  721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 15/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.05 s, sys: 58.6 ms, total: 3.11 s\n",
      "Wall time: 785 ms\n",
      "confusion matrix\n",
      " [[ 0  0 12  2  0]\n",
      " [ 0  0 16  2  0]\n",
      " [ 0  0 19  6  0]\n",
      " [ 0  0 21  3  0]\n",
      " [ 0  0 20  2  0]]\n",
      "Weighted Confusion Matrix Score:  766\n",
      "SCIKIT*****\n",
      "CPU times: user 123 ms, sys: 1.43 ms, total: 125 ms\n",
      "Wall time: 31.2 ms\n",
      "Validation Acc: 0.242718446602\n",
      "confusion matrix\n",
      " [[ 0 12  2  0  0]\n",
      " [ 0 16  2  0  0]\n",
      " [ 0 19  6  0  0]\n",
      " [ 0 21  3  0  0]\n",
      " [ 0 20  2  0  0]]\n",
      "Weighted Confusion Matrix Score:  721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 15/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.93 s, sys: 43.5 ms, total: 2.97 s\n",
      "Wall time: 748 ms\n",
      "confusion matrix\n",
      " [[ 0  0  0  1 12]\n",
      " [ 0  0  1  2 15]\n",
      " [ 0  0  1  3 21]\n",
      " [ 0  0  1  2 21]\n",
      " [ 0  0  1  1 20]]\n",
      "Weighted Confusion Matrix Score:  1453\n",
      "SCIKIT*****\n",
      "CPU times: user 109 ms, sys: 1.75 ms, total: 111 ms\n",
      "Wall time: 27.8 ms\n",
      "Validation Acc: 0.235294117647\n",
      "confusion matrix\n",
      " [[ 0  0  1 12  0]\n",
      " [ 0  1  2 15  0]\n",
      " [ 0  1  3 21  0]\n",
      " [ 0  1  2 21  0]\n",
      " [ 0  1  1 20  0]]\n",
      "Weighted Confusion Matrix Score:  981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 15/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.91 s, sys: 53.2 ms, total: 2.96 s\n",
      "Wall time: 746 ms\n",
      "confusion matrix\n",
      " [[ 0  0 13  0  0]\n",
      " [ 0  0 18  0  0]\n",
      " [ 0  0 24  0  0]\n",
      " [ 0  0 24  0  0]\n",
      " [ 0  0 22  0  0]]\n",
      "Weighted Confusion Matrix Score:  707\n",
      "SCIKIT*****\n",
      "CPU times: user 111 ms, sys: 2.02 ms, total: 113 ms\n",
      "Wall time: 28.4 ms\n",
      "Validation Acc: 0.237623762376\n",
      "confusion matrix\n",
      " [[ 0 13  0  0  0]\n",
      " [ 0 18  0  0  0]\n",
      " [ 0 24  0  0  0]\n",
      " [ 0 24  0  0  0]\n",
      " [ 0 22  0  0  0]]\n",
      "Weighted Confusion Matrix Score:  707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 15/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.96 s, sys: 58.9 ms, total: 3.02 s\n",
      "Wall time: 763 ms\n",
      "confusion matrix\n",
      " [[ 0  0 10  3  0]\n",
      " [ 0  0 11  5  2]\n",
      " [ 0  0 15  8  1]\n",
      " [ 0  0 14  9  1]\n",
      " [ 0  0 10  8  4]]\n",
      "Weighted Confusion Matrix Score:  870\n",
      "SCIKIT*****\n",
      "CPU times: user 74.6 ms, sys: 1.38 ms, total: 76 ms\n",
      "Wall time: 19 ms\n",
      "Validation Acc: 0.237623762376\n",
      "confusion matrix\n",
      " [[ 0 10  3  0  0]\n",
      " [ 0 11  5  2  0]\n",
      " [ 0 15  8  1  0]\n",
      " [ 0 14  9  1  0]\n",
      " [ 0 10  8  4  0]]\n",
      "Weighted Confusion Matrix Score:  731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 15/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.1 s, sys: 57.7 ms, total: 3.16 s\n",
      "Wall time: 799 ms\n",
      "confusion matrix\n",
      " [[ 0  0 12  1  0]\n",
      " [ 0  0 15  3  0]\n",
      " [ 0  0 19  5  0]\n",
      " [ 0  0 15  8  1]\n",
      " [ 0  0 14  7  1]]\n",
      "Weighted Confusion Matrix Score:  795\n",
      "SCIKIT*****\n",
      "CPU times: user 81.4 ms, sys: 1.23 ms, total: 82.7 ms\n",
      "Wall time: 20.7 ms\n",
      "Validation Acc: 0.237623762376\n",
      "confusion matrix\n",
      " [[ 0 12  1  0  0]\n",
      " [ 0 15  3  0  0]\n",
      " [ 0 19  5  0  0]\n",
      " [ 0 15  8  1  0]\n",
      " [ 0 14  7  1  0]]\n",
      "Weighted Confusion Matrix Score:  713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 15/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.08 s, sys: 68.7 ms, total: 3.15 s\n",
      "Wall time: 797 ms\n",
      "confusion matrix\n",
      " [[ 0  0  0 12  1]\n",
      " [ 0  0  0 17  0]\n",
      " [ 0  0  0 24  0]\n",
      " [ 0  0  0 22  2]\n",
      " [ 0  0  0 22  0]]\n",
      "Weighted Confusion Matrix Score:  1015\n",
      "SCIKIT*****\n",
      "CPU times: user 124 ms, sys: 2.48 ms, total: 126 ms\n",
      "Wall time: 31.8 ms\n",
      "Validation Acc: 0.24\n",
      "confusion matrix\n",
      " [[ 0  0 12  1  0]\n",
      " [ 0  0 17  0  0]\n",
      " [ 0  0 24  0  0]\n",
      " [ 0  0 22  2  0]\n",
      " [ 0  0 22  0  0]]\n",
      "Weighted Confusion Matrix Score:  709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 15/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.15 s, sys: 89.1 ms, total: 3.24 s\n",
      "Wall time: 825 ms\n",
      "confusion matrix\n",
      " [[ 0  0  6  0  7]\n",
      " [ 0  0  9  1  7]\n",
      " [ 0  0 12  5  7]\n",
      " [ 0  0 11  0 13]\n",
      " [ 0  0  4  1 17]]\n",
      "Weighted Confusion Matrix Score:  1129\n",
      "SCIKIT*****\n",
      "CPU times: user 77.3 ms, sys: 1.33 ms, total: 78.7 ms\n",
      "Wall time: 19.7 ms\n",
      "Validation Acc: 0.24\n",
      "confusion matrix\n",
      " [[ 0  6  0  7  0]\n",
      " [ 0  9  1  7  0]\n",
      " [ 0 12  5  7  0]\n",
      " [ 0 11  0 13  0]\n",
      " [ 0  4  1 17  0]]\n",
      "Weighted Confusion Matrix Score:  853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 15/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.15 s, sys: 53.6 ms, total: 3.2 s\n",
      "Wall time: 808 ms\n",
      "confusion matrix\n",
      " [[ 0  0 13  0  0]\n",
      " [ 0  0 17  0  0]\n",
      " [ 0  0 24  0  0]\n",
      " [ 0  0 23  0  0]\n",
      " [ 0  0 22  0  0]]\n",
      "Weighted Confusion Matrix Score:  693\n",
      "SCIKIT*****\n",
      "CPU times: user 47.9 ms, sys: 911 s, total: 48.8 ms\n",
      "Wall time: 12.2 ms\n",
      "Validation Acc: 0.242424242424\n",
      "confusion matrix\n",
      " [[ 0 13  0  0  0]\n",
      " [ 0 17  0  0  0]\n",
      " [ 0 24  0  0  0]\n",
      " [ 0 23  0  0  0]\n",
      " [ 0 22  0  0  0]]\n",
      "Weighted Confusion Matrix Score:  693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 15/15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.8 s, sys: 38.7 ms, total: 2.84 s\n",
      "Wall time: 714 ms\n",
      "confusion matrix\n",
      " [[ 0  0  9  4  0]\n",
      " [ 0  0 15  2  0]\n",
      " [ 0  0 13 11  0]\n",
      " [ 0  0 11 12  0]\n",
      " [ 0  0 13  8  0]]\n",
      "Weighted Confusion Matrix Score:  797\n",
      "SCIKIT*****\n",
      "CPU times: user 86.4 ms, sys: 1.39 ms, total: 87.8 ms\n",
      "Wall time: 22.8 ms\n",
      "Validation Acc: 0.234693877551\n",
      "confusion matrix\n",
      " [[ 0  9  4  0  0]\n",
      " [ 0 15  2  0  0]\n",
      " [ 0 13 11  0  0]\n",
      " [ 0 11 12  0  0]\n",
      " [ 0 13  8  0  0]]\n",
      "Weighted Confusion Matrix Score:  686\n"
     ]
    }
   ],
   "source": [
    "vals = {'n_hidden':50, \n",
    "         'C':1e-2, 'epochs':15, 'eta':0.001, \n",
    "         'alpha':0.0, 'decrease_const':1e-9, 'minibatches':200,\n",
    "         'shuffle':True,'random_state':1, \n",
    "           'nonlinearity': \"sigmoid\"}\n",
    "custom_performances = []\n",
    "custom_times = []\n",
    "custom_mem = []\n",
    "sk_performances = []\n",
    "sk_times = []\n",
    "sk_mem = []\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "            \n",
    "            # I will create new variables here so that it is more obvious what \n",
    "            # the code is doing (you can compact this syntax and avoid duplicating memory,\n",
    "            # but it makes this code less readable)\n",
    "            X_train = (X[train_indices])\n",
    "            y_train = y[train_indices]\n",
    "\n",
    "            X_test = (X[test_indices])\n",
    "            y_test = y[test_indices]\n",
    "\n",
    "            nn_long_sigmoid = TLPGaussianInitialQuad(**vals)\n",
    "           \n",
    "\n",
    "            #%time nn_long_sigmoid.fit(X_train, y_train, print_progress=1, XY_test=(X_test,y_test))\n",
    "            st = time.time()\n",
    "\n",
    "            mem = memory_usage((nn_long_sigmoid.fit,(X_train,y_train))) # train object\n",
    "            t = (time.time() -st)\n",
    "            custom_times.append(t)\n",
    "            custom_mem.append(mem[0])\n",
    "\n",
    "            %time nn_long_sigmoid.fit(X_train, y_train, print_progress=1)\n",
    "            y_hat = nn_long_sigmoid.predict(X_test) # get test set precitions\n",
    "\n",
    "            # now let's get the accuracy and confusion matrix for this iterations of training/testing\n",
    "            acc = mt.accuracy_score(y_test,y_hat+1)\n",
    "    #         lr_clf_accuracies.append(acc)\n",
    "    #         cost_accuracies.append([acc])\n",
    "\n",
    "            conf = mt.confusion_matrix(y_test,y_hat+1)\n",
    "#             print(vals)\n",
    "#                     print_result(nn_long_sigmoid,X_train,y_train,X_test,y_test,title=\"Long Run\",color=\"red\")\n",
    "#                     plt.show()\n",
    "            print(\"confusion matrix\\n\",conf)\n",
    "            score = get_confusion_costTot(conf, cost_matrix)\n",
    "            print(\"Weighted Confusion Matrix Score: \", score)\n",
    "            custom_performances.append(score)\n",
    "            \n",
    "            clf = MLPClassifier(hidden_layer_sizes=(50, ), \n",
    "                        activation='relu', # type of non-linearity, every layer\n",
    "                        solver='sgd', \n",
    "                        alpha=1e-4, # L2 penalty\n",
    "                        batch_size= 'auto', # min of 200, num_samples\n",
    "                        learning_rate='constant', # adapt learning? only for sgd\n",
    "                        learning_rate_init=0.1, # only SGD\n",
    "                        power_t=0.0,    # only SGD with inverse scaling of learning rate\n",
    "                        max_iter=75, # stopping criteria\n",
    "                        shuffle=True, \n",
    "                        random_state=1, \n",
    "                        tol=0, # for stopping\n",
    "                        verbose=False, \n",
    "                        warm_start=False, \n",
    "                        momentum=0.9, # only SGD\n",
    "                        nesterovs_momentum=False, # only SGD\n",
    "                        early_stopping=False, \n",
    "                        validation_fraction=0.0, # only if early_stop is true\n",
    "                        beta_1=0.9, # adam decay rate of moment\n",
    "                        beta_2=0.999, # adam decay rate of moment\n",
    "                        epsilon=1e-08) # adam numerical stabilizer\n",
    "            \n",
    "            print(\"SCIKIT*****\")\n",
    "            \n",
    "            st = time.time()\n",
    "\n",
    "            mem = memory_usage((clfd.fit,(X_train,y_train))) # train object\n",
    "            t = (time.time() -st)\n",
    "            custom_times.append(t)\n",
    "            custom_mem.append(mem[0])\n",
    "            %time clf.fit(X_train,y_train)\n",
    "            yhat = clf.predict(X_test)\n",
    "            print('Validation Acc:',accuracy_score(yhat,y_test))\n",
    "            conf = mt.confusion_matrix(y_test,y_hat)\n",
    "                    #             print(vals)\n",
    "            #                     print_result(nn_long_sigmoid,X_train,y_train,X_test,y_test,title=\"Long Run\",color=\"red\")\n",
    "            #                     plt.show()\n",
    "            print(\"confusion matrix\\n\",conf)\n",
    "            score = get_confusion_costTot(conf, cost_matrix)\n",
    "            print(\"Weighted Confusion Matrix Score: \", score)\n",
    "            sk_performances.append(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(y_test.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Implementations in terms of Generalization Performance, Computation Time, and Memory Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(sk_performances)\n",
    "print(custom_performances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.boxplot([sk_performances,custom_performances])\n",
    "plt.title(\"Comparing Generalization Perfomances\")\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Generalization Performances')\n",
    "plt.xticks([1,2],['SKL','OURS'])\n",
    "plt.figure()\n",
    "print((time.time() -st)*100)\n",
    "# ax = fig.add_subplot(111)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.boxplot([lr_sk_times,lr_clf_times])\n",
    "plt.title(\"Comparing Training Times\")\n",
    "plt.xlabel('Implementation of Logistic Regression')\n",
    "plt.ylabel('Training Time (seconds) ')\n",
    "plt.xticks([1,2],['SKL','OURS'])\n",
    "plt.figure()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
